{"cells":[{"cell_type":"markdown","metadata":{"id":"G-ZevDCjTyjv"},"source":["# Using the same code as before, please solve the following exercises\n","\n","    2. Play around with the learning rate. Values like 0.00001, 0.0001, 0.001, 0.1, 1 are all interesting to observe. \n","    \n","    \n","Useful tip: When you change something, don't forget to RERUN all cells. This can be done easily by clicking:\n","Kernel -> Restart & Run All\n","If you don't do that, your algorithm will keep the OLD values of all parameters.\n","\n","## Solution\n","\n","Find the piece of code that chooses the optimization algorithm. Change the learning_rate argument to 1.\n","\n","Here are some takeaways:\n","1. It takes the algorithm the same time to finish working.\n","2. The loss DIVERGES TO INFINITY.\n","3. The weights and biases are completely random and extremely big (in fact their value is nan).\n","4. More iterations would not solve the issue, as the loss is not converging.\n","5. The problem IS NOT SOLVED.\n","6. The final graph cannot be printed as all outputs are nan."]},{"cell_type":"markdown","metadata":{"id":"kgoec-dOTyjz"},"source":["## Import the relevant libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"E023IJoNTyj0","executionInfo":{"status":"ok","timestamp":1672929191733,"user_tz":-330,"elapsed":4142,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}}},"outputs":[],"source":["# We must always import the relevant libraries for our problem at hand. NumPy and TensorFlow are required for this example.\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf"]},{"cell_type":"markdown","metadata":{"id":"cLR6K3vbTyj2"},"source":["## Data generation\n","\n","We generate data using the exact same logic and code as the example from the previous notebook. The only difference now is that we save it to an npz file. Npz is numpy's file type which allows you to save numpy arrays into a single .npz file. We introduce this change because in machine learning most often: \n","\n","* you are given some data (csv, database, etc.)\n","* you preprocess it into a desired format (later on we will see methods for preprocesing)\n","* you save it into npz files (if you're working in Python) to access later\n","\n","Nothing to worry about - this is literally saving your NumPy arrays into a file that you can later access, nothing more."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OEJK0W1dTyj3","executionInfo":{"status":"ok","timestamp":1672929197530,"user_tz":-330,"elapsed":580,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}}},"outputs":[],"source":["# First, we should declare a variable containing the size of the training set we want to generate.\n","observations = 1000\n","\n","# We will work with two variables as inputs. You can think about them as x1 and x2 in our previous examples.\n","# We have picked x and z, since it is easier to differentiate them.\n","# We generate them randomly, drawing from an uniform distribution. There are 3 arguments of this method (low, high, size).\n","# The size of xs and zs is observations x 1. In this case: 1000 x 1.\n","xs = np.random.uniform(low=-10, high=10, size=(observations,1))\n","zs = np.random.uniform(-10, 10, (observations,1))\n","\n","# Combine the two dimensions of the input into one input matrix. \n","# This is the X matrix from the linear model y = x*w + b.\n","# column_stack is a Numpy method, which combines two matrices (vectors) into one.\n","generated_inputs = np.column_stack((xs,zs))\n","\n","# We add a random small noise to the function i.e. f(x,z) = 2x - 3z + 5 + <small noise>\n","noise = np.random.uniform(-1, 1, (observations,1))\n","\n","# Produce the targets according to our f(x,z) = 2x - 3z + 5 + noise definition.\n","# In this way, we are basically saying: the weights should be 2 and -3, while the bias is 5.\n","generated_targets = 2*xs - 3*zs + 5 + noise\n","\n","# save into an npz file called \"TF_intro\"\n","np.savez('TF_intro', inputs=generated_inputs, targets=generated_targets)"]},{"cell_type":"markdown","metadata":{"id":"95BP_xbATyj4"},"source":["## Solving with TensorFlow\n","\n","<i/>Note: This intro is just the basics of TensorFlow which has way more capabilities and depth than that.<i>"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"1ALR4dflTyj5","executionInfo":{"status":"ok","timestamp":1672929201995,"user_tz":-330,"elapsed":963,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}}},"outputs":[],"source":["# Load the training data from the NPZ\n","training_data = np.load('TF_intro.npz')"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0bltQykMTyj5","executionInfo":{"status":"ok","timestamp":1672929215781,"user_tz":-330,"elapsed":11777,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}},"outputId":"6f82dd93-e927-41cd-a540-dfe0b041d072"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n","32/32 - 1s - loss: nan - 571ms/epoch - 18ms/step\n","Epoch 2/100\n","32/32 - 0s - loss: nan - 43ms/epoch - 1ms/step\n","Epoch 3/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 4/100\n","32/32 - 0s - loss: nan - 36ms/epoch - 1ms/step\n","Epoch 5/100\n","32/32 - 0s - loss: nan - 35ms/epoch - 1ms/step\n","Epoch 6/100\n","32/32 - 0s - loss: nan - 37ms/epoch - 1ms/step\n","Epoch 7/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 8/100\n","32/32 - 0s - loss: nan - 55ms/epoch - 2ms/step\n","Epoch 9/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 10/100\n","32/32 - 0s - loss: nan - 38ms/epoch - 1ms/step\n","Epoch 11/100\n","32/32 - 0s - loss: nan - 41ms/epoch - 1ms/step\n","Epoch 12/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 13/100\n","32/32 - 0s - loss: nan - 40ms/epoch - 1ms/step\n","Epoch 14/100\n","32/32 - 0s - loss: nan - 36ms/epoch - 1ms/step\n","Epoch 15/100\n","32/32 - 0s - loss: nan - 45ms/epoch - 1ms/step\n","Epoch 16/100\n","32/32 - 0s - loss: nan - 36ms/epoch - 1ms/step\n","Epoch 17/100\n","32/32 - 0s - loss: nan - 44ms/epoch - 1ms/step\n","Epoch 18/100\n","32/32 - 0s - loss: nan - 38ms/epoch - 1ms/step\n","Epoch 19/100\n","32/32 - 0s - loss: nan - 56ms/epoch - 2ms/step\n","Epoch 20/100\n","32/32 - 0s - loss: nan - 40ms/epoch - 1ms/step\n","Epoch 21/100\n","32/32 - 0s - loss: nan - 42ms/epoch - 1ms/step\n","Epoch 22/100\n","32/32 - 0s - loss: nan - 54ms/epoch - 2ms/step\n","Epoch 23/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 24/100\n","32/32 - 0s - loss: nan - 40ms/epoch - 1ms/step\n","Epoch 25/100\n","32/32 - 0s - loss: nan - 38ms/epoch - 1ms/step\n","Epoch 26/100\n","32/32 - 0s - loss: nan - 37ms/epoch - 1ms/step\n","Epoch 27/100\n","32/32 - 0s - loss: nan - 37ms/epoch - 1ms/step\n","Epoch 28/100\n","32/32 - 0s - loss: nan - 37ms/epoch - 1ms/step\n","Epoch 29/100\n","32/32 - 0s - loss: nan - 38ms/epoch - 1ms/step\n","Epoch 30/100\n","32/32 - 0s - loss: nan - 46ms/epoch - 1ms/step\n","Epoch 31/100\n","32/32 - 0s - loss: nan - 37ms/epoch - 1ms/step\n","Epoch 32/100\n","32/32 - 0s - loss: nan - 43ms/epoch - 1ms/step\n","Epoch 33/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 34/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 35/100\n","32/32 - 0s - loss: nan - 40ms/epoch - 1ms/step\n","Epoch 36/100\n","32/32 - 0s - loss: nan - 37ms/epoch - 1ms/step\n","Epoch 37/100\n","32/32 - 0s - loss: nan - 41ms/epoch - 1ms/step\n","Epoch 38/100\n","32/32 - 0s - loss: nan - 38ms/epoch - 1ms/step\n","Epoch 39/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 40/100\n","32/32 - 0s - loss: nan - 44ms/epoch - 1ms/step\n","Epoch 41/100\n","32/32 - 0s - loss: nan - 41ms/epoch - 1ms/step\n","Epoch 42/100\n","32/32 - 0s - loss: nan - 42ms/epoch - 1ms/step\n","Epoch 43/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 44/100\n","32/32 - 0s - loss: nan - 39ms/epoch - 1ms/step\n","Epoch 45/100\n","32/32 - 0s - loss: nan - 57ms/epoch - 2ms/step\n","Epoch 46/100\n","32/32 - 0s - loss: nan - 40ms/epoch - 1ms/step\n","Epoch 47/100\n","32/32 - 0s - loss: nan - 46ms/epoch - 1ms/step\n","Epoch 48/100\n","32/32 - 0s - loss: nan - 48ms/epoch - 1ms/step\n","Epoch 49/100\n","32/32 - 0s - loss: nan - 56ms/epoch - 2ms/step\n","Epoch 50/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 51/100\n","32/32 - 0s - loss: nan - 42ms/epoch - 1ms/step\n","Epoch 52/100\n","32/32 - 0s - loss: nan - 53ms/epoch - 2ms/step\n","Epoch 53/100\n","32/32 - 0s - loss: nan - 48ms/epoch - 1ms/step\n","Epoch 54/100\n","32/32 - 0s - loss: nan - 54ms/epoch - 2ms/step\n","Epoch 55/100\n","32/32 - 0s - loss: nan - 60ms/epoch - 2ms/step\n","Epoch 56/100\n","32/32 - 0s - loss: nan - 53ms/epoch - 2ms/step\n","Epoch 57/100\n","32/32 - 0s - loss: nan - 61ms/epoch - 2ms/step\n","Epoch 58/100\n","32/32 - 0s - loss: nan - 60ms/epoch - 2ms/step\n","Epoch 59/100\n","32/32 - 0s - loss: nan - 67ms/epoch - 2ms/step\n","Epoch 60/100\n","32/32 - 0s - loss: nan - 55ms/epoch - 2ms/step\n","Epoch 61/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 62/100\n","32/32 - 0s - loss: nan - 52ms/epoch - 2ms/step\n","Epoch 63/100\n","32/32 - 0s - loss: nan - 70ms/epoch - 2ms/step\n","Epoch 64/100\n","32/32 - 0s - loss: nan - 49ms/epoch - 2ms/step\n","Epoch 65/100\n","32/32 - 0s - loss: nan - 95ms/epoch - 3ms/step\n","Epoch 66/100\n","32/32 - 0s - loss: nan - 50ms/epoch - 2ms/step\n","Epoch 67/100\n","32/32 - 0s - loss: nan - 46ms/epoch - 1ms/step\n","Epoch 68/100\n","32/32 - 0s - loss: nan - 49ms/epoch - 2ms/step\n","Epoch 69/100\n","32/32 - 0s - loss: nan - 55ms/epoch - 2ms/step\n","Epoch 70/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 71/100\n","32/32 - 0s - loss: nan - 48ms/epoch - 1ms/step\n","Epoch 72/100\n","32/32 - 0s - loss: nan - 43ms/epoch - 1ms/step\n","Epoch 73/100\n","32/32 - 0s - loss: nan - 49ms/epoch - 2ms/step\n","Epoch 74/100\n","32/32 - 0s - loss: nan - 43ms/epoch - 1ms/step\n","Epoch 75/100\n","32/32 - 0s - loss: nan - 54ms/epoch - 2ms/step\n","Epoch 76/100\n","32/32 - 0s - loss: nan - 51ms/epoch - 2ms/step\n","Epoch 77/100\n","32/32 - 0s - loss: nan - 48ms/epoch - 2ms/step\n","Epoch 78/100\n","32/32 - 0s - loss: nan - 69ms/epoch - 2ms/step\n","Epoch 79/100\n","32/32 - 0s - loss: nan - 56ms/epoch - 2ms/step\n","Epoch 80/100\n","32/32 - 0s - loss: nan - 66ms/epoch - 2ms/step\n","Epoch 81/100\n","32/32 - 0s - loss: nan - 53ms/epoch - 2ms/step\n","Epoch 82/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 83/100\n","32/32 - 0s - loss: nan - 45ms/epoch - 1ms/step\n","Epoch 84/100\n","32/32 - 0s - loss: nan - 49ms/epoch - 2ms/step\n","Epoch 85/100\n","32/32 - 0s - loss: nan - 46ms/epoch - 1ms/step\n","Epoch 86/100\n","32/32 - 0s - loss: nan - 65ms/epoch - 2ms/step\n","Epoch 87/100\n","32/32 - 0s - loss: nan - 54ms/epoch - 2ms/step\n","Epoch 88/100\n","32/32 - 0s - loss: nan - 48ms/epoch - 1ms/step\n","Epoch 89/100\n","32/32 - 0s - loss: nan - 43ms/epoch - 1ms/step\n","Epoch 90/100\n","32/32 - 0s - loss: nan - 44ms/epoch - 1ms/step\n","Epoch 91/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 92/100\n","32/32 - 0s - loss: nan - 41ms/epoch - 1ms/step\n","Epoch 93/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n","Epoch 94/100\n","32/32 - 0s - loss: nan - 45ms/epoch - 1ms/step\n","Epoch 95/100\n","32/32 - 0s - loss: nan - 43ms/epoch - 1ms/step\n","Epoch 96/100\n","32/32 - 0s - loss: nan - 49ms/epoch - 2ms/step\n","Epoch 97/100\n","32/32 - 0s - loss: nan - 55ms/epoch - 2ms/step\n","Epoch 98/100\n","32/32 - 0s - loss: nan - 46ms/epoch - 1ms/step\n","Epoch 99/100\n","32/32 - 0s - loss: nan - 57ms/epoch - 2ms/step\n","Epoch 100/100\n","32/32 - 0s - loss: nan - 47ms/epoch - 1ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ffa9bc14040>"]},"metadata":{},"execution_count":4}],"source":["# Declare a variable where we will store the input size of our model\n","# It should be equal to the number of variables you have\n","input_size = 2\n","# Declare the output size of the model\n","# It should be equal to the number of outputs you've got (for regressions that's usually 1)\n","output_size = 1\n","\n","# Outline the model\n","# We lay out the model in 'Sequential'\n","# Note that there are no calculations involved - we are just describing our network\n","model = tf.keras.Sequential([\n","                            # Each 'layer' is listed here\n","                            # The method 'Dense' indicates, our mathematical operation to be (xw + b)\n","                            tf.keras.layers.Dense(output_size,\n","                                                 # there are extra arguments you can include to customize your model\n","                                                 # in our case we are just trying to create a solution that is \n","                                                 # as close as possible to our NumPy model\n","                                                 kernel_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1),\n","                                                 bias_initializer=tf.random_uniform_initializer(minval=-0.1, maxval=0.1)\n","                                                 )\n","                            ])\n","\n","# We can also define a custom optimizer, where we can specify the learning rate\n","custom_optimizer = tf.keras.optimizers.SGD(learning_rate=1)\n","# Note that sometimes you may also need a custom loss function \n","# That's much harder to implement and won't be covered in this course though\n","\n","# 'compile' is the place where you select and indicate the optimizers and the loss\n","model.compile(optimizer=custom_optimizer, loss='mean_squared_error')\n","\n","# finally we fit the model, indicating the inputs and targets\n","# if they are not otherwise specified the number of epochs will be 1 (a single epoch of training), \n","# so the number of epochs is 'kind of' mandatory, too\n","# we can play around with verbose; we prefer verbose=2\n","model.fit(training_data['inputs'], training_data['targets'], epochs=100, verbose=2)"]},{"cell_type":"markdown","metadata":{"id":"q6_Yt8VrTyj9"},"source":["## Extract the weights and bias\n","Extracting the weight(s) and bias(es) of a model is not an essential step for the machine learning process. In fact, usually they would not tell us much in a deep learning context. However, this simple example was set up in a way, which allows us to verify if the answers we get are correct."]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkuyDRUCTyj-","executionInfo":{"status":"ok","timestamp":1672929258165,"user_tz":-330,"elapsed":9,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}},"outputId":"a62f2551-47c6-4f14-db5e-d779c79cd919"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[nan],\n","        [nan]], dtype=float32), array([nan], dtype=float32)]"]},"metadata":{},"execution_count":5}],"source":["# Extracting the weights and biases is achieved quite easily\n","model.layers[0].get_weights()"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5H6ERStxTyj_","executionInfo":{"status":"ok","timestamp":1672929258648,"user_tz":-330,"elapsed":15,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}},"outputId":"d1fa1669-a3ab-42af-e075-eff4c6daf138"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[nan],\n","       [nan]], dtype=float32)"]},"metadata":{},"execution_count":6}],"source":["# We can save the weights and biases in separate variables for easier examination\n","# Note that there can be hundreds or thousands of them!\n","weights = model.layers[0].get_weights()[0]\n","weights"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pJFqPp52TykA","executionInfo":{"status":"ok","timestamp":1672929258650,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}},"outputId":"cd6ac6e9-1d00-4bb7-fa5d-a19c6226692c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([nan], dtype=float32)"]},"metadata":{},"execution_count":7}],"source":["# We can save the weights and biases in separate variables for easier examination\n","# Note that there can be hundreds or thousands of them!\n","bias = model.layers[0].get_weights()[1]\n","bias"]},{"cell_type":"markdown","metadata":{"id":"CzvrPAZVTykC"},"source":["## Extract the outputs (make predictions)\n","Once more, this is not an essential step, however, we usually want to be able to make predictions."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2MGG3E9uTykC","executionInfo":{"status":"ok","timestamp":1672929266634,"user_tz":-330,"elapsed":497,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}},"outputId":"8fc1a773-1c16-4f95-db7f-927b9c023897"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan],\n","       [nan]], dtype=float32)"]},"metadata":{},"execution_count":8}],"source":["# We can predict new values in order to actually make use of the model\n","# Sometimes it is useful to round the values to be able to read the output\n","# Usually we use this method on NEW DATA, rather than our original training data\n","model.predict_on_batch(training_data['inputs']).round(1)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mhrBy188TykD","outputId":"151f797e-a85d-4212-a93c-18f41f9140cd"},"outputs":[{"data":{"text/plain":["array([[ -7.8],\n","       [ 21.1],\n","       [ -8.5],\n","       [-22. ],\n","       [ -2.8],\n","       [  2.4],\n","       [ 17.8],\n","       [  8.6],\n","       [ 20.5],\n","       [  8.2],\n","       [-13.6],\n","       [ -8.7],\n","       [-27.2],\n","       [ 26.7],\n","       [ 14.7],\n","       [  3.6],\n","       [-11.4],\n","       [  6.3],\n","       [  6.8],\n","       [ -6.8],\n","       [-13.6],\n","       [ 16.2],\n","       [ 24.6],\n","       [  6. ],\n","       [ 11. ],\n","       [ 52.7],\n","       [ 28.7],\n","       [-22.2],\n","       [-18.7],\n","       [  0.8],\n","       [ 23.8],\n","       [-35.6],\n","       [ 27. ],\n","       [ 15.3],\n","       [-33.8],\n","       [ 18.7],\n","       [ 27.6],\n","       [ -4.2],\n","       [ 44.6],\n","       [ 26.7],\n","       [  1.2],\n","       [ 10.6],\n","       [  3.1],\n","       [ 21.3],\n","       [-35.8],\n","       [ 48.9],\n","       [ 10.1],\n","       [ -6.9],\n","       [ 15.1],\n","       [ -4.9],\n","       [ 15.9],\n","       [ 15.2],\n","       [ 19.1],\n","       [  0.6],\n","       [ -3.3],\n","       [ 16.2],\n","       [ 35.8],\n","       [  8. ],\n","       [-18. ],\n","       [ -1.6],\n","       [ -9.4],\n","       [ -0.6],\n","       [-15. ],\n","       [ 28.3],\n","       [  7.1],\n","       [ 12.6],\n","       [ -0.2],\n","       [  4.1],\n","       [ 17.3],\n","       [ 39.7],\n","       [ 17.3],\n","       [ 12.6],\n","       [ -7.1],\n","       [ 45.4],\n","       [ 34.6],\n","       [-28.4],\n","       [ -3.4],\n","       [  4. ],\n","       [ -2.3],\n","       [-16.5],\n","       [-17. ],\n","       [ 20.4],\n","       [ -1.6],\n","       [  9.2],\n","       [-20.1],\n","       [-11.6],\n","       [-13.4],\n","       [-24.5],\n","       [-33.1],\n","       [ -5.8],\n","       [-12.4],\n","       [ 26.5],\n","       [ 18.8],\n","       [ -7.7],\n","       [ -9.4],\n","       [-17.7],\n","       [ 25.7],\n","       [ 21.2],\n","       [ 17. ],\n","       [-11. ],\n","       [ -1.8],\n","       [-20.3],\n","       [-23. ],\n","       [  4.8],\n","       [ 27.2],\n","       [  2.7],\n","       [-22.1],\n","       [ 36.4],\n","       [  4.8],\n","       [-14.4],\n","       [-18.7],\n","       [  9.2],\n","       [ -7.4],\n","       [-23.4],\n","       [ 21.5],\n","       [-27.9],\n","       [ -5.4],\n","       [-18.3],\n","       [ 28.9],\n","       [-27.9],\n","       [ -9.4],\n","       [  7.3],\n","       [-27.8],\n","       [ 23.8],\n","       [  4.4],\n","       [ 37.9],\n","       [ 19.6],\n","       [-29.8],\n","       [ 15.4],\n","       [  1. ],\n","       [-18.6],\n","       [ -1.8],\n","       [ 17. ],\n","       [-14.6],\n","       [ -3.2],\n","       [ 41.5],\n","       [-35.5],\n","       [ -7.9],\n","       [-11.1],\n","       [ 39.3],\n","       [-18.7],\n","       [ -6.4],\n","       [-28.7],\n","       [ -3.2],\n","       [ 44.5],\n","       [ -2. ],\n","       [  3.9],\n","       [ 21.3],\n","       [ 37.5],\n","       [-30.8],\n","       [ -2.8],\n","       [ 11.9],\n","       [ 12.2],\n","       [ 35.5],\n","       [ 12.6],\n","       [  9.4],\n","       [ 19. ],\n","       [ -1.5],\n","       [ 19.2],\n","       [-28. ],\n","       [  4.7],\n","       [ 30.1],\n","       [ -4.6],\n","       [  7.3],\n","       [ 20.7],\n","       [ 37.3],\n","       [ 34. ],\n","       [ -2.9],\n","       [-17.3],\n","       [-31.3],\n","       [ 14.2],\n","       [ 11.5],\n","       [ -5.2],\n","       [  5.1],\n","       [ -4.4],\n","       [ 23.6],\n","       [-12.5],\n","       [  7.6],\n","       [ 18.9],\n","       [ -9.3],\n","       [-21.5],\n","       [  3.7],\n","       [ 12.4],\n","       [ 22.9],\n","       [ 33.6],\n","       [ 27.3],\n","       [ -7.3],\n","       [-19.6],\n","       [ 16.5],\n","       [ -6.8],\n","       [ 12.9],\n","       [ 23.1],\n","       [  8.5],\n","       [-26.4],\n","       [ 26.3],\n","       [ 22.8],\n","       [ 49.1],\n","       [-13.4],\n","       [  3.4],\n","       [ 30.9],\n","       [  7. ],\n","       [  9.3],\n","       [  7.5],\n","       [ 42.5],\n","       [-10.2],\n","       [-15. ],\n","       [ 23.6],\n","       [ 27.4],\n","       [ 31.4],\n","       [-18.6],\n","       [  6.8],\n","       [  4.8],\n","       [ -2.5],\n","       [-14.4],\n","       [ 29.6],\n","       [ 26.9],\n","       [-11.5],\n","       [ -5.9],\n","       [  6.1],\n","       [ -8. ],\n","       [ 27.8],\n","       [  8.8],\n","       [ -8.7],\n","       [ 26.4],\n","       [ 29.3],\n","       [ 35.6],\n","       [ 18.2],\n","       [-13.2],\n","       [-16.4],\n","       [ 23. ],\n","       [-20.3],\n","       [ 32.9],\n","       [ 39.1],\n","       [ 25. ],\n","       [  6.9],\n","       [ 48.2],\n","       [ -7.5],\n","       [ 20.4],\n","       [-15. ],\n","       [ 25.1],\n","       [-43.6],\n","       [-11.7],\n","       [-11. ],\n","       [ 34.9],\n","       [-19.3],\n","       [ 12.4],\n","       [-43.8],\n","       [  4.9],\n","       [ 30.6],\n","       [ -6. ],\n","       [-18.1],\n","       [ -9.6],\n","       [-34.6],\n","       [-15.9],\n","       [  9.2],\n","       [-30.6],\n","       [ 27.7],\n","       [ 24. ],\n","       [ 33.2],\n","       [ 36. ],\n","       [ 37.4],\n","       [-27. ],\n","       [ -0.3],\n","       [-29.5],\n","       [  2.9],\n","       [ 10.7],\n","       [ 13.1],\n","       [  9.2],\n","       [-41.8],\n","       [ 11.8],\n","       [  4.9],\n","       [ -1.6],\n","       [ 34.9],\n","       [-15.6],\n","       [ -7.1],\n","       [ 24.8],\n","       [  0.3],\n","       [-33.5],\n","       [ -8.3],\n","       [  2.9],\n","       [ 18. ],\n","       [ 17.2],\n","       [  4. ],\n","       [  6.4],\n","       [-13. ],\n","       [-33.9],\n","       [ 36.5],\n","       [ 30.7],\n","       [ -3.9],\n","       [-35.9],\n","       [-10.9],\n","       [  9.6],\n","       [ 25.9],\n","       [-12.7],\n","       [  4.7],\n","       [-16. ],\n","       [-10.9],\n","       [ -0.4],\n","       [ 32.7],\n","       [-13. ],\n","       [-14.2],\n","       [ -8.8],\n","       [ 31.2],\n","       [ 38.9],\n","       [ 35.9],\n","       [ 25.9],\n","       [-29.8],\n","       [-17.1],\n","       [ 12.8],\n","       [-29. ],\n","       [ 19.4],\n","       [  9.6],\n","       [ 13.6],\n","       [-16.9],\n","       [-26.8],\n","       [-32.3],\n","       [ 43.9],\n","       [ -4.2],\n","       [ 27.2],\n","       [ -6.5],\n","       [ 16.2],\n","       [ -8.8],\n","       [-16.8],\n","       [ -6.4],\n","       [-23.6],\n","       [  9.6],\n","       [ 13.4],\n","       [-15.3],\n","       [ -7.6],\n","       [  4.5],\n","       [-10.1],\n","       [-16.8],\n","       [ 31.6],\n","       [ 10.7],\n","       [ -0.9],\n","       [ -0.6],\n","       [ 52.6],\n","       [-21.8],\n","       [ 45.2],\n","       [  1.8],\n","       [-17.7],\n","       [ 20.3],\n","       [  4.8],\n","       [-19. ],\n","       [-29.9],\n","       [ 22.5],\n","       [ 33.3],\n","       [  2.4],\n","       [ -7.5],\n","       [ 17.4],\n","       [-17.1],\n","       [ -7.6],\n","       [ 34.4],\n","       [-13.6],\n","       [ 52.7],\n","       [ 35.2],\n","       [  8.2],\n","       [-31.4],\n","       [  5.9],\n","       [ 13.8],\n","       [ 23.2],\n","       [ 38.9],\n","       [ 26.6],\n","       [ 28. ],\n","       [ 25.6],\n","       [ 28.9],\n","       [  5.1],\n","       [-24.1],\n","       [ 39.6],\n","       [ 38.1],\n","       [ 40.4],\n","       [ 43.2],\n","       [-42.2],\n","       [  2.6],\n","       [ 12.6],\n","       [  7.2],\n","       [ 16.3],\n","       [-10.5],\n","       [-34.5],\n","       [ 27.8],\n","       [  8.2],\n","       [ 13.3],\n","       [ -1.8],\n","       [ -0.5],\n","       [ 24.3],\n","       [ 17. ],\n","       [-19.5],\n","       [-12.6],\n","       [-33.4],\n","       [-16.2],\n","       [ 29.1],\n","       [  6.6],\n","       [ 24.6],\n","       [  1.6],\n","       [ 48.9],\n","       [-10.2],\n","       [  4.9],\n","       [ -5.7],\n","       [-17.8],\n","       [ 31.3],\n","       [ 17.7],\n","       [-30.7],\n","       [-24.2],\n","       [-22.3],\n","       [-22.8],\n","       [ 14.1],\n","       [ 16.2],\n","       [ 17.3],\n","       [-19.6],\n","       [ 19.5],\n","       [-10.9],\n","       [-27.6],\n","       [  2.7],\n","       [ 17.6],\n","       [ 18.1],\n","       [ -3.5],\n","       [ -7.4],\n","       [-12.3],\n","       [ 25.8],\n","       [-26.1],\n","       [  4.6],\n","       [  7.9],\n","       [  8.1],\n","       [ -0.9],\n","       [-19.3],\n","       [ 34.9],\n","       [ 22.5],\n","       [ 32.8],\n","       [ 36.5],\n","       [-30.2],\n","       [-24.6],\n","       [  6.8],\n","       [ -9.5],\n","       [ 14.5],\n","       [-26.5],\n","       [-33. ],\n","       [ 36.9],\n","       [-22.6],\n","       [ 16. ],\n","       [  4.7],\n","       [-13.2],\n","       [ 36.8],\n","       [-13.8],\n","       [ 42.2],\n","       [ 38.5],\n","       [-19.9],\n","       [-19.9],\n","       [ 41.4],\n","       [ 38. ],\n","       [ 24.3],\n","       [  7.2],\n","       [ -6. ],\n","       [  8.1],\n","       [  1.2],\n","       [-11.8],\n","       [ 10.7],\n","       [  1.2],\n","       [  6.1],\n","       [ 33. ],\n","       [  3. ],\n","       [ 25.5],\n","       [-19.3],\n","       [-25.9],\n","       [  5.1],\n","       [-19.1],\n","       [  6. ],\n","       [ 11.6],\n","       [-17.7],\n","       [ 36.1],\n","       [-35.8],\n","       [-10.5],\n","       [ 33. ],\n","       [ -1.7],\n","       [ 44.5],\n","       [ 23.6],\n","       [  6.2],\n","       [ 25.7],\n","       [ 15.1],\n","       [ -1.9],\n","       [ 15.7],\n","       [ 26. ],\n","       [ 10.3],\n","       [  4.5],\n","       [ 28.2],\n","       [ -5.8],\n","       [-30.6],\n","       [ -9.8],\n","       [ 24.5],\n","       [ 21. ],\n","       [ -7.4],\n","       [-30.2],\n","       [ 28.1],\n","       [ 26.1],\n","       [ -5. ],\n","       [ -6.7],\n","       [  0.1],\n","       [ 15. ],\n","       [  0.3],\n","       [ 18. ],\n","       [ 21.2],\n","       [ -1.8],\n","       [ -3.6],\n","       [ 31.5],\n","       [  0.9],\n","       [  0.5],\n","       [-11. ],\n","       [  3.1],\n","       [ 40.3],\n","       [ 30. ],\n","       [-11.1],\n","       [ -3. ],\n","       [-19.2],\n","       [ 25.8],\n","       [-13.6],\n","       [ 22.9],\n","       [  9.9],\n","       [-33.1],\n","       [ 14.3],\n","       [ 24.4],\n","       [ 30.4],\n","       [-19.7],\n","       [-19.1],\n","       [-33.6],\n","       [ -2.6],\n","       [ 45. ],\n","       [ 27.1],\n","       [ -8.7],\n","       [ 31.2],\n","       [  5.4],\n","       [-18.5],\n","       [ -4.3],\n","       [ 45.5],\n","       [ 13. ],\n","       [  1.6],\n","       [ 17. ],\n","       [ 10.9],\n","       [-17.2],\n","       [-19.1],\n","       [ 12.3],\n","       [ 30. ],\n","       [-24.7],\n","       [ 42.5],\n","       [ 24.6],\n","       [-13.7],\n","       [  6.1],\n","       [-32.7],\n","       [ 13.9],\n","       [-16.1],\n","       [-21. ],\n","       [  7.1],\n","       [ -7.2],\n","       [-12.6],\n","       [ 33.5],\n","       [  3.4],\n","       [ 15.9],\n","       [  0.6],\n","       [ 10.4],\n","       [ 10.8],\n","       [-22.3],\n","       [ 44.5],\n","       [ 12. ],\n","       [ 30.4],\n","       [ 20.5],\n","       [ 24.5],\n","       [-26.2],\n","       [  6.5],\n","       [ 29.1],\n","       [  0.3],\n","       [-15.6],\n","       [ -3.5],\n","       [ -4.1],\n","       [  8.7],\n","       [-29.5],\n","       [-26.8],\n","       [ 17.6],\n","       [-21.1],\n","       [ 48.8],\n","       [  1.4],\n","       [ 17.5],\n","       [ 20.8],\n","       [-14.4],\n","       [  9.7],\n","       [  7.3],\n","       [-14.6],\n","       [-12.7],\n","       [  6. ],\n","       [-33.2],\n","       [-21.9],\n","       [  9.5],\n","       [-36.5],\n","       [ 28.7],\n","       [ 12.4],\n","       [ 12.1],\n","       [-33. ],\n","       [ 44.1],\n","       [-16.9],\n","       [ -8. ],\n","       [ 17.1],\n","       [  6.6],\n","       [ 25. ],\n","       [ 20.2],\n","       [-23.9],\n","       [ -2.5],\n","       [ 24.4],\n","       [  0.5],\n","       [ 27.7],\n","       [ -2.6],\n","       [ 17.1],\n","       [-12.7],\n","       [  1.2],\n","       [ 39.4],\n","       [ 43.5],\n","       [ 12.6],\n","       [-11.4],\n","       [ 25.9],\n","       [  5.5],\n","       [-13.1],\n","       [ 17.4],\n","       [ 15.4],\n","       [ -0.4],\n","       [ 14.3],\n","       [  5.9],\n","       [ 29.6],\n","       [  9.1],\n","       [ 10.5],\n","       [ 17.3],\n","       [  8. ],\n","       [ 16.2],\n","       [ 49.4],\n","       [ 11.5],\n","       [-11.5],\n","       [  9. ],\n","       [-13.4],\n","       [ -3.9],\n","       [ 10.8],\n","       [ 35.4],\n","       [ -1.6],\n","       [-16.1],\n","       [-13.9],\n","       [  5. ],\n","       [-21. ],\n","       [ 11.7],\n","       [  0.2],\n","       [ 26.4],\n","       [ -1.1],\n","       [-14.6],\n","       [ 39.1],\n","       [ 31.6],\n","       [ 18.9],\n","       [ 26.8],\n","       [  1.6],\n","       [-24.3],\n","       [ 27.3],\n","       [ 17.2],\n","       [ 49.5],\n","       [ 24.8],\n","       [ -6.7],\n","       [ 23.1],\n","       [  4.5],\n","       [ 32.2],\n","       [ 15.8],\n","       [ 37.3],\n","       [ -4.4],\n","       [ 14.8],\n","       [ 10.8],\n","       [-17. ],\n","       [ -7.8],\n","       [-30.2],\n","       [ -4.4],\n","       [  0.2],\n","       [ 28.2],\n","       [-16.1],\n","       [ -8.4],\n","       [ 35.2],\n","       [-10. ],\n","       [-11.7],\n","       [ 27.9],\n","       [ 11.7],\n","       [ 19.7],\n","       [ 24. ],\n","       [  8.2],\n","       [  3.7],\n","       [-24.7],\n","       [-14. ],\n","       [  9.7],\n","       [ 28.7],\n","       [ -8.4],\n","       [ -8. ],\n","       [  7. ],\n","       [ 13.2],\n","       [ 14.7],\n","       [-20.8],\n","       [ 40.3],\n","       [-31.1],\n","       [-33.9],\n","       [ 28. ],\n","       [ 10.4],\n","       [ -4.2],\n","       [-31.2],\n","       [  7.6],\n","       [ 38. ],\n","       [ -5.5],\n","       [ 13.3],\n","       [  8. ],\n","       [ 22.8],\n","       [ -4.8],\n","       [-29.1],\n","       [-26.1],\n","       [ -6.5],\n","       [-10.8],\n","       [  2. ],\n","       [ -0. ],\n","       [ -6.4],\n","       [  7.7],\n","       [ 24.4],\n","       [ 21. ],\n","       [  5.7],\n","       [ 20.6],\n","       [  9.8],\n","       [-15.6],\n","       [ 19.7],\n","       [ 25. ],\n","       [ 13.8],\n","       [-33.7],\n","       [ 13. ],\n","       [-24. ],\n","       [-17.6],\n","       [ -2.4],\n","       [  3.7],\n","       [ 43.9],\n","       [ -7.2],\n","       [ 30. ],\n","       [-23.2],\n","       [ 12.8],\n","       [ 33. ],\n","       [ 18.7],\n","       [  5.5],\n","       [-12.7],\n","       [  8.4],\n","       [-19.7],\n","       [ -9.9],\n","       [ 19.7],\n","       [ 34. ],\n","       [ 18.5],\n","       [ 17.6],\n","       [  6.4],\n","       [  8.7],\n","       [ 31.3],\n","       [ 31.8],\n","       [  7.3],\n","       [ -3.9],\n","       [ 21.1],\n","       [ 30.9],\n","       [ 20.4],\n","       [-25.7],\n","       [ -4.7],\n","       [ 54.3],\n","       [-11.1],\n","       [-33.4],\n","       [ -7.2],\n","       [ 24.6],\n","       [-10.1],\n","       [ -0.4],\n","       [ -0.1],\n","       [ 36.5],\n","       [  9.8],\n","       [ 42.5],\n","       [  7.8],\n","       [ -5.9],\n","       [ 21.4],\n","       [ 18.8],\n","       [ 37.3],\n","       [ 19.2],\n","       [  3.4],\n","       [ 15.2],\n","       [ 26.5],\n","       [ 15.8],\n","       [ 47.6],\n","       [ 10. ],\n","       [ 14.1],\n","       [ 15.3],\n","       [-17.6],\n","       [  2.2],\n","       [-20.8],\n","       [ -9.2],\n","       [ -3.8],\n","       [-14.5],\n","       [ 43.7],\n","       [-17.6],\n","       [ -5.3],\n","       [-24.9],\n","       [  0.9],\n","       [-24.4],\n","       [  8.6],\n","       [ -9.8],\n","       [ 19.2],\n","       [ 15. ],\n","       [  9.9],\n","       [ -5.3],\n","       [ 16.1],\n","       [ 32.2],\n","       [ 29.3],\n","       [ 31.7],\n","       [ 42.4],\n","       [ 21.7],\n","       [  4.4],\n","       [  9.1],\n","       [ 19.1],\n","       [ 12.5],\n","       [-22.7],\n","       [ 32.8],\n","       [-14. ],\n","       [-16.4],\n","       [ -0.6],\n","       [ 20.8],\n","       [-10.9],\n","       [ 16.6],\n","       [ 12.6],\n","       [ -9.3],\n","       [ 17. ],\n","       [ 33.4],\n","       [ -5.3],\n","       [ 28.1],\n","       [-18.6],\n","       [-42.9],\n","       [  7.3],\n","       [ -0.2],\n","       [ 21.2],\n","       [ -3.2],\n","       [  2.6],\n","       [ 13. ],\n","       [ 17.7],\n","       [-25.2],\n","       [-31.6],\n","       [-10.9],\n","       [ 22.2],\n","       [-21.1],\n","       [ -2. ],\n","       [ -3.2],\n","       [ -6.5],\n","       [ -7.9],\n","       [ 49.9],\n","       [  3.6],\n","       [ -3.4],\n","       [ 19.8],\n","       [-25.3],\n","       [ -8.9],\n","       [ -4.6],\n","       [  1.4],\n","       [-22.5],\n","       [ 29.7],\n","       [-16.7],\n","       [  6.2],\n","       [ 22.4],\n","       [ 13.1],\n","       [-19. ],\n","       [-14.7],\n","       [  2.7],\n","       [  9.4],\n","       [ 21.3],\n","       [ -2.3],\n","       [-12.4],\n","       [ 15.3],\n","       [ 26.3],\n","       [ -8.1],\n","       [  9.8],\n","       [ 15.3],\n","       [ 12.3],\n","       [-38.5],\n","       [ -7.5],\n","       [ -4.1],\n","       [-41.1],\n","       [ 48.7],\n","       [  2. ],\n","       [ -8.6],\n","       [ 38.4],\n","       [ -9.8],\n","       [ -0.3],\n","       [ 35.6],\n","       [ 25.7],\n","       [ -6.8],\n","       [  6.3],\n","       [-21.9],\n","       [-20.3],\n","       [ 34.1],\n","       [ 27.2],\n","       [ 25.2],\n","       [ 22.5],\n","       [  8.1],\n","       [ 51.2],\n","       [-25.9],\n","       [-13.3],\n","       [ -4.2],\n","       [ -5. ],\n","       [-28.9],\n","       [ -6.9],\n","       [ 13.2],\n","       [-32.8],\n","       [ -2.5],\n","       [ 11.6],\n","       [-29.2],\n","       [ -1.6],\n","       [ 46.2],\n","       [  6.9],\n","       [-35.5],\n","       [ -4.7],\n","       [  5.1],\n","       [ 16.2],\n","       [-21.8],\n","       [ 53.5],\n","       [ 11.9],\n","       [  0.3],\n","       [  8.1],\n","       [ 42.3],\n","       [ 52.9],\n","       [-14.7],\n","       [-14.9],\n","       [-12.7],\n","       [ 32.3],\n","       [ 20.8],\n","       [ 29.9],\n","       [ -7. ],\n","       [-31.6],\n","       [ 18.4],\n","       [-13.1],\n","       [ -9.4],\n","       [ 16. ],\n","       [  7.3],\n","       [  5. ],\n","       [ 32.7],\n","       [ 40.2],\n","       [ 23.9],\n","       [-25.3],\n","       [-29.4],\n","       [ 15.2],\n","       [ 13.2],\n","       [-11.5],\n","       [ 23.3],\n","       [ -4.7],\n","       [ 10.4],\n","       [-14.7],\n","       [  8.2],\n","       [ 42.3],\n","       [ 39.9],\n","       [-36.6],\n","       [-13.5],\n","       [-18.2],\n","       [ 19.3],\n","       [  5.3],\n","       [ 19. ],\n","       [ -5.9],\n","       [ 15.7],\n","       [ -7.7],\n","       [-24. ],\n","       [ 22.6],\n","       [ 11. ],\n","       [ -9.2],\n","       [ 24.8],\n","       [ -5.8],\n","       [ -0.1],\n","       [-13.2],\n","       [  3.1],\n","       [ 13.9],\n","       [ 48. ],\n","       [ 18.7],\n","       [-11.1],\n","       [-21.7],\n","       [-24.6],\n","       [ -9.7],\n","       [-10.5],\n","       [ 23. ],\n","       [ -7.3],\n","       [ 15.1],\n","       [ 41.7],\n","       [ 14.9],\n","       [ 39.3],\n","       [ 18. ],\n","       [-24.2],\n","       [  7. ],\n","       [ 14.7],\n","       [ 45.9],\n","       [-11.6],\n","       [ -9.5],\n","       [ 29.1],\n","       [-12.8],\n","       [ 33.7],\n","       [-22.1],\n","       [ 19.7],\n","       [ -2.4],\n","       [  0.4],\n","       [ 17.5],\n","       [ 16.5],\n","       [-10.5],\n","       [ 23.1],\n","       [ 18.3],\n","       [ -3.4],\n","       [-20.5],\n","       [  0.2],\n","       [ -1.7],\n","       [  1.6]])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["# If we display our targets (actual observed values), we can manually compare the outputs and the targets\n","training_data['targets'].round(1)"]},{"cell_type":"markdown","metadata":{"id":"cQfvJsTCTykE"},"source":["## Plotting the data"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":279},"id":"osBU1170TykE","executionInfo":{"status":"ok","timestamp":1672929309274,"user_tz":-330,"elapsed":1045,"user":{"displayName":"Rohit Rathod 13","userId":"07063012775989601403"}},"outputId":"ce0fac16-6fa8-48df-c7aa-c47adeddd513"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["# The model is optimized, so the outputs are calculated based on the last form of the model\n","\n","# We have to np.squeeze the arrays in order to fit them to what the plot function expects.\n","# Doesn't change anything as we cut dimensions of size 1 - just a technicality.\n","plt.plot(np.squeeze(model.predict_on_batch(training_data['inputs'])), np.squeeze(training_data['targets']))\n","plt.xlabel('outputs')\n","plt.ylabel('targets')\n","plt.show()\n","\n","# Voila - what you see should be exactly the same as in the previous notebook!\n","# You probably don't see the point of TensorFlow now - it took us the same number of lines of code\n","# to achieve this simple result. However, once we go deeper in the next chapter,\n","# TensorFlow will save us hundreds of lines of code."]},{"cell_type":"code","source":[],"metadata":{"id":"aFDYgZfvW2iM"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python [conda env:python3.7_TF2.0]","language":"python","name":"conda-env-python3.7_TF2.0-py"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}